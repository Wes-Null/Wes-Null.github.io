library(tidyverse)
library(cluster)
library(factoextra)
library(readr)
library(pheatmap)

### MACHINE LEARNING SCRIPT ###
### ITERATIVE CLUSTERING ###

Spotify_df <- read_csv("C:/Users/dis90/Downloads/Spotify_Top_Songs_Global_May_29_2025 (2).csv")

Spotify_df$exists = 1

### PIVOT WIDE ###

spotify_wide <- Spotify_df |>
  pivot_wider(names_from = country, values_from = exists, id_cols = c(track_name, artist_names))

spotify_wide <- spotify_wide %>%
  mutate(across(everything(), ~ifelse(is.na(.), 0, .)))

### ROUND ONE CLUSTERING ###

### Sample first

sample <- 2000

round_one_sample <- spotify_wide |>
  sample_n(sample)

jaccard_mat <- dist(round_one_sample[,3:ncol(round_one_sample)])

# Complete Linkage
hc_complete_sample <- agnes(jaccard_mat, method = "complete")

# This one line of code runs the silhouette analysis
round_one_cut <- fviz_nbclust(
  x = as.matrix(jaccard_mat),
  FUNcluster = function(x, k) { list(cluster = cutree(hc_complete_sample, k = k)) },
  method = "silhouette",
  k.max = 20  # You can adjust the max number of clusters to test
) +
  labs(title = "Optimal Number of Clusters (Silhouette Method)")

round_one_cut

jaccard_whole <- dist(spotify_wide[,3:ncol(spotify_wide)])

hc_complete <- agnes(jaccard_whole, method = "complete")

spotify_wide$cluster <- cutree(hc_complete, k = 4)

cluster8 <- spotify_wide |>
  filter(cluster == 8)

cluster7 <- spotify_wide |>
  filter(cluster == 7)

cluster6 <- spotify_wide |>
  filter(cluster == 6)

cluster5 <- spotify_wide |>
  filter(cluster == 5)

cluster4 <- spotify_wide |>
  filter(cluster == 4)
cluster3 <- spotify_wide |>
  filter(cluster == 3)
cluster2 <- spotify_wide |>
  filter(cluster == 2)
cluster1 <- spotify_wide |>
  filter(cluster == 1)

colSums(cluster3[,-(1:2)])
## NORTHERN EUROPE, UK, US
## DISTINCTLY AMERICAN CLUSTER
colSums(cluster2[,-(1:2)])
## DISTINCTLY SOUTH AMERICAN
## INCLUDES SOME KOREAN ARTISTS

### TRY WARDS ###

hc_wards_sample <- agnes(jaccard_mat, method = "ward")

# This one line of code runs the silhouette analysis
round_one_cut_2 <- fviz_nbclust(
  x = as.matrix(jaccard_mat),
  FUNcluster = function(x, k) { list(cluster = cutree(hc_wards_sample, k = k)) },
  method = "silhouette",
  k.max = 20  # You can adjust the max number of clusters to test
) +
  labs(title = "Optimal Number of Clusters (Silhouette Method)")

round_one_cut_2

hc_wards <- agnes(jaccard_whole, method = "ward")

ward_cluster_round_one <- spotify_wide |>
  mutate(cluster = cutree(hc_wards, k = 2))

ward_one <- ward_cluster_round_one |>
  filter(cluster == 1)

ward_two <- ward_cluster_round_one |>
  filter(cluster == 2)

ward_one_pct <- colSums(ward_one[, -(1:2)]) / nrow(ward_one)
ward_one_pct

tail(sort(ward_one_pct), 10)

ward_two_pct <- colSums(ward_two[, -(1:2)]) / nrow(ward_two)
ward_two_pct

tail(sort(ward_two_pct), 10)

### COMPARE COMPLETE AND WARD

# Complete Linkage
corr_complete <- cor(jaccard_whole, cophenetic(hc_complete))

# Ward's Method
corr_ward <- cor(jaccard_whole, cophenetic(hc_wards))

corr_complete
corr_ward

### WARD ###

### BREAKING DOWN CLUSTER 1: COMPLETE LINKAGE ###

cluster1_sample <- cluster1 |>
  sample_n(sample)

jaccard_cluster1_sample <- dist(cluster1_sample[,3:ncol(cluster1_sample)])

# Complete Linkage
hc_complete_c1_sample <- agnes(jaccard_cluster1_sample, method = "complete")

# This one line of code runs the silhouette analysis
cluster1_cut <- fviz_nbclust(
  x = as.matrix(jaccard_cluster1_sample),
  FUNcluster = function(x, k) { list(cluster = cutree(hc_complete_c1_sample, k = k)) },
  method = "silhouette",
  k.max = 20  # You can adjust the max number of clusters to test
) +
  labs(title = "Optimal Number of Clusters (Silhouette Method)")

cluster1_cut

### k = 3

jaccard_cluster1 <- dist(cluster1[,3:ncol(cluster1)])

hc_complete_cluster1 <- agnes(jaccard_cluster1, method = "complete")

cluster1$round_two_cluster <- cutree(hc_complete_cluster1, k =)
